{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d69b66",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Train some new embeddings (S2V, MS2DS), while leaving out spectra belonging to certain inchikeys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db518984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/louwe015/miniconda3/envs/spec_analysis8/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gensim\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple, List\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f56ed095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "ALL_GNPS_210409_positive_cleaned_peaks_processed\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/mnt/LTR_userdata/hooft001/mass_spectral_embeddings/datasets/ALL_GNPS_210409_positive/\"\n",
    "embedding_path = \"/mnt/LTR_userdata/hooft001/mass_spectral_embeddings/embeddings/ALL_GNPS_210409_positive/\"\n",
    "\n",
    "path_models = os.path.join(embedding_path, \"cca_test_set\")\n",
    "\n",
    "train_inchis_file = os.path.join(path_models, \"train_inchikeys.txt\")\n",
    "print(os.path.exists(train_inchis_file))\n",
    "\n",
    "processed_spectrums_file = os.path.join(data_path, \"ALL_GNPS_210409_positive_cleaned_peaks_processed_s2v.pickle\")\n",
    "print(os.path.exists(processed_spectrums_file))\n",
    "\n",
    "base = \"ALL_GNPS_210409_positive_cleaned_peaks_processed\"\n",
    "print(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e7235",
   "metadata": {},
   "source": [
    "## Filter out spectra\n",
    "Only include spectra with inchikeys from train_inchikeys file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "702cb6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7293\n"
     ]
    }
   ],
   "source": [
    "# read train_inchis_file\n",
    "with open(train_inchis_file) as inf:\n",
    "    line = inf.readline()\n",
    "    train_inchikeys = line.strip(\" ,\").split(\", \")  # strip comma from end\n",
    "print(len(train_inchikeys))  # should be 7293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4147e7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['IYDKWWDUBYWQGF', 'KNGPFNUOXXLKCN', 'CGZKSPLDUIRCIO'],\n",
       " ['PWAOOJDMFUQOKB', 'QRYRORQUOLYVBU', 'KBPHJBAIARWVSC'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inchikeys[:3], train_inchikeys[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1181cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read processed spectra\n",
    "spectrums_processed = pickle.load(open(processed_spectrums_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7929651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199780"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spectrums_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99580f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79475"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrums_filtered = []\n",
    "set_inchi14_train = set(train_inchikeys)\n",
    "for spec in spectrums_processed:\n",
    "    inchikey = spec.metadata.get(\"inchikey\")\n",
    "    if inchikey:\n",
    "        if inchikey[:14] in set_inchi14_train:\n",
    "            spectrums_filtered.append(spec)\n",
    "len(spectrums_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dcd6012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7293"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see if same amount (7293) of inchikeys still exist\n",
    "len(set(spec.metadata.get(\"inchikey\")[:14] for spec in spectrums_filtered if spec.metadata.get(\"inchikey\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00160f",
   "metadata": {},
   "source": [
    "## Spec2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e2dfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec2vec import SpectrumDocument\n",
    "documents_spectrums_filtered = [SpectrumDocument(s, n_decimals=2) for s in spectrums_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c0615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/LTR_userdata/hooft001/mass_spectral_embeddings/datasets/ALL_GNPS_210409_positive/ALL_GNPS_210409_positive_cleaned_peaks_processed_spec2vec_embedding.model\n",
      "  Epoch 1 of 15.Change in loss after epoch 1: 3521952.75\n",
      "  Epoch 2 of 15.Change in loss after epoch 2: 2881441.75\n",
      "  Epoch 3 of 15.Change in loss after epoch 3: 2442946.5\n",
      "  Epoch 4 of 15.Change in loss after epoch 4: 2096941.0\n",
      "  Epoch 5 of 15.Change in loss after epoch 5: 2107511.0\n",
      "  Epoch 6 of 15.Change in loss after epoch 6: 2002219.0\n",
      "  Epoch 7 of 15.Change in loss after epoch 7: 1905996.0\n",
      "  Epoch 8 of 15.Change in loss after epoch 8: 1492440.0\n",
      "  Epoch 9 of 15.Change in loss after epoch 9: 1492570.0\n",
      "  Epoch 10 of 15.Change in loss after epoch 10: 1427834.0\n",
      "  Epoch 11 of 15.Change in loss after epoch 11: 1331980.0\n",
      "  Epoch 12 of 15.Change in loss after epoch 12: 1307482.0\n",
      "  Epoch 13 of 15.Change in loss after epoch 13: 1275600.0\n",
      "  Epoch 14 of 15.Change in loss after epoch 14: 1205648.0\n",
      "  Epoch 15 of 15.Change in loss after epoch 15: 1204638.0\n",
      "Saving model with name: /mnt/LTR_userdata/hooft001/mass_spectral_embeddings/datasets/ALL_GNPS_210409_positive/ALL_GNPS_210409_positive_cleaned_peaks_processed_spec2vec_embedding.model\n"
     ]
    }
   ],
   "source": [
    "from spec2vec.model_building import train_new_word2vec_model\n",
    "import glob\n",
    "\n",
    "model_file = os.path.join(path_models, base+\"_only_train_spec2vec_embedding.model\")\n",
    "print(model_file)\n",
    "\n",
    "find_model = glob.glob(os.path.join(path_models, base+\"_only_train_spec2vec*\"))\n",
    "if len(find_model) == 0:\n",
    "    iterations = [15]\n",
    "    # Train model with default parameters\n",
    "    model = train_new_word2vec_model(documents_spectrums_filtered, iterations, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30889a3",
   "metadata": {},
   "source": [
    "## MS2DeepScore (10000 -> 500 -> 500 = 200)\n",
    "Currently I trained without validation data, but put 40 epochs of training analogous to MS2Query model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45c5e430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_of_peaks = [len(s.peaks) for s in spectrums_filtered]\n",
    "plt.hist(numbers_of_peaks, np.linspace(0,1000,20))\n",
    "plt.xlim(0, max(numbers_of_peaks))\n",
    "\n",
    "print(max(numbers_of_peaks))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b55bf638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STZYTFJPGGDRJD</th>\n",
       "      <th>SWTDXMBCOHIACK</th>\n",
       "      <th>HJBWJAPEBGSQPR</th>\n",
       "      <th>VQNWOYVWHDVFJY</th>\n",
       "      <th>WFDXOXNFNRHQEC</th>\n",
       "      <th>GZLIPAFSJXROEC</th>\n",
       "      <th>YTZSBJLNMIQROD</th>\n",
       "      <th>FOULCGVQZYQEQM</th>\n",
       "      <th>BPSJMBKZSUTYNF</th>\n",
       "      <th>PZJVSTTVMXPZCJ</th>\n",
       "      <th>...</th>\n",
       "      <th>VLSRUFWCGBMYDJ</th>\n",
       "      <th>SXXHPCVDFDABHW</th>\n",
       "      <th>MRHAPHFJBAUDTR</th>\n",
       "      <th>ZYCWGZVLCXRARB</th>\n",
       "      <th>CGUNOWXWUXNOPE</th>\n",
       "      <th>MGRVRXRGTBOSHW</th>\n",
       "      <th>WELCNKRQSNXMDQ</th>\n",
       "      <th>XFANDVLPSBUGKD</th>\n",
       "      <th>NDTYTMIUWGWIMO</th>\n",
       "      <th>OAUIRSVJXOFAOO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STZYTFJPGGDRJD</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377404</td>\n",
       "      <td>0.124056</td>\n",
       "      <td>0.269856</td>\n",
       "      <td>0.233411</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.354221</td>\n",
       "      <td>0.227136</td>\n",
       "      <td>0.277537</td>\n",
       "      <td>0.316971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112832</td>\n",
       "      <td>0.177950</td>\n",
       "      <td>0.277099</td>\n",
       "      <td>0.308905</td>\n",
       "      <td>0.341988</td>\n",
       "      <td>0.017219</td>\n",
       "      <td>0.274643</td>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.138404</td>\n",
       "      <td>0.270531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWTDXMBCOHIACK</th>\n",
       "      <td>0.377404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.158318</td>\n",
       "      <td>0.274962</td>\n",
       "      <td>0.297240</td>\n",
       "      <td>0.324305</td>\n",
       "      <td>0.372534</td>\n",
       "      <td>0.216172</td>\n",
       "      <td>0.274742</td>\n",
       "      <td>0.351300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140399</td>\n",
       "      <td>0.184380</td>\n",
       "      <td>0.325533</td>\n",
       "      <td>0.353607</td>\n",
       "      <td>0.387618</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.364401</td>\n",
       "      <td>0.371447</td>\n",
       "      <td>0.153314</td>\n",
       "      <td>0.366841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HJBWJAPEBGSQPR</th>\n",
       "      <td>0.124056</td>\n",
       "      <td>0.158318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159198</td>\n",
       "      <td>0.209205</td>\n",
       "      <td>0.200203</td>\n",
       "      <td>0.133133</td>\n",
       "      <td>0.106944</td>\n",
       "      <td>0.201604</td>\n",
       "      <td>0.157643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.152395</td>\n",
       "      <td>0.180529</td>\n",
       "      <td>0.188280</td>\n",
       "      <td>0.147473</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.199245</td>\n",
       "      <td>0.234842</td>\n",
       "      <td>0.074725</td>\n",
       "      <td>0.180833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VQNWOYVWHDVFJY</th>\n",
       "      <td>0.269856</td>\n",
       "      <td>0.274962</td>\n",
       "      <td>0.159198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.270677</td>\n",
       "      <td>0.261011</td>\n",
       "      <td>0.218063</td>\n",
       "      <td>0.237487</td>\n",
       "      <td>0.228497</td>\n",
       "      <td>0.471683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.216159</td>\n",
       "      <td>0.591716</td>\n",
       "      <td>0.370402</td>\n",
       "      <td>0.279240</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>0.314224</td>\n",
       "      <td>0.100515</td>\n",
       "      <td>0.262040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WFDXOXNFNRHQEC</th>\n",
       "      <td>0.233411</td>\n",
       "      <td>0.297240</td>\n",
       "      <td>0.209205</td>\n",
       "      <td>0.270677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329466</td>\n",
       "      <td>0.273837</td>\n",
       "      <td>0.184561</td>\n",
       "      <td>0.258525</td>\n",
       "      <td>0.355102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194030</td>\n",
       "      <td>0.212011</td>\n",
       "      <td>0.330603</td>\n",
       "      <td>0.312870</td>\n",
       "      <td>0.318026</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.319708</td>\n",
       "      <td>0.357045</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.351071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MGRVRXRGTBOSHW</th>\n",
       "      <td>0.017219</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>0.016904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WELCNKRQSNXMDQ</th>\n",
       "      <td>0.274643</td>\n",
       "      <td>0.364401</td>\n",
       "      <td>0.199245</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>0.319708</td>\n",
       "      <td>0.498774</td>\n",
       "      <td>0.291818</td>\n",
       "      <td>0.206495</td>\n",
       "      <td>0.290592</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>0.203997</td>\n",
       "      <td>0.346317</td>\n",
       "      <td>0.368841</td>\n",
       "      <td>0.374494</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413747</td>\n",
       "      <td>0.113171</td>\n",
       "      <td>0.409401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XFANDVLPSBUGKD</th>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.371447</td>\n",
       "      <td>0.234842</td>\n",
       "      <td>0.314224</td>\n",
       "      <td>0.357045</td>\n",
       "      <td>0.368529</td>\n",
       "      <td>0.304927</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.318118</td>\n",
       "      <td>0.425359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197961</td>\n",
       "      <td>0.218633</td>\n",
       "      <td>0.381903</td>\n",
       "      <td>0.373005</td>\n",
       "      <td>0.397096</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.413747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092946</td>\n",
       "      <td>0.407524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDTYTMIUWGWIMO</th>\n",
       "      <td>0.138404</td>\n",
       "      <td>0.153314</td>\n",
       "      <td>0.074725</td>\n",
       "      <td>0.100515</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.115589</td>\n",
       "      <td>0.146286</td>\n",
       "      <td>0.143836</td>\n",
       "      <td>0.090047</td>\n",
       "      <td>0.093234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073460</td>\n",
       "      <td>0.069132</td>\n",
       "      <td>0.089494</td>\n",
       "      <td>0.114688</td>\n",
       "      <td>0.134598</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>0.113171</td>\n",
       "      <td>0.092946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAUIRSVJXOFAOO</th>\n",
       "      <td>0.270531</td>\n",
       "      <td>0.366841</td>\n",
       "      <td>0.180833</td>\n",
       "      <td>0.262040</td>\n",
       "      <td>0.351071</td>\n",
       "      <td>0.396333</td>\n",
       "      <td>0.302090</td>\n",
       "      <td>0.176124</td>\n",
       "      <td>0.293212</td>\n",
       "      <td>0.370438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160504</td>\n",
       "      <td>0.220690</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.360963</td>\n",
       "      <td>0.362445</td>\n",
       "      <td>0.016904</td>\n",
       "      <td>0.409401</td>\n",
       "      <td>0.407524</td>\n",
       "      <td>0.086003</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17106 rows × 17106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                STZYTFJPGGDRJD  SWTDXMBCOHIACK  HJBWJAPEBGSQPR  \\\n",
       "STZYTFJPGGDRJD        1.000000        0.377404        0.124056   \n",
       "SWTDXMBCOHIACK        0.377404        1.000000        0.158318   \n",
       "HJBWJAPEBGSQPR        0.124056        0.158318        1.000000   \n",
       "VQNWOYVWHDVFJY        0.269856        0.274962        0.159198   \n",
       "WFDXOXNFNRHQEC        0.233411        0.297240        0.209205   \n",
       "...                        ...             ...             ...   \n",
       "MGRVRXRGTBOSHW        0.017219        0.014911        0.005848   \n",
       "WELCNKRQSNXMDQ        0.274643        0.364401        0.199245   \n",
       "XFANDVLPSBUGKD        0.298611        0.371447        0.234842   \n",
       "NDTYTMIUWGWIMO        0.138404        0.153314        0.074725   \n",
       "OAUIRSVJXOFAOO        0.270531        0.366841        0.180833   \n",
       "\n",
       "                VQNWOYVWHDVFJY  WFDXOXNFNRHQEC  GZLIPAFSJXROEC  \\\n",
       "STZYTFJPGGDRJD        0.269856        0.233411        0.258824   \n",
       "SWTDXMBCOHIACK        0.274962        0.297240        0.324305   \n",
       "HJBWJAPEBGSQPR        0.159198        0.209205        0.200203   \n",
       "VQNWOYVWHDVFJY        1.000000        0.270677        0.261011   \n",
       "WFDXOXNFNRHQEC        0.270677        1.000000        0.329466   \n",
       "...                        ...             ...             ...   \n",
       "MGRVRXRGTBOSHW        0.014306        0.017301        0.017957   \n",
       "WELCNKRQSNXMDQ        0.288416        0.319708        0.498774   \n",
       "XFANDVLPSBUGKD        0.314224        0.357045        0.368529   \n",
       "NDTYTMIUWGWIMO        0.100515        0.083333        0.115589   \n",
       "OAUIRSVJXOFAOO        0.262040        0.351071        0.396333   \n",
       "\n",
       "                YTZSBJLNMIQROD  FOULCGVQZYQEQM  BPSJMBKZSUTYNF  \\\n",
       "STZYTFJPGGDRJD        0.354221        0.227136        0.277537   \n",
       "SWTDXMBCOHIACK        0.372534        0.216172        0.274742   \n",
       "HJBWJAPEBGSQPR        0.133133        0.106944        0.201604   \n",
       "VQNWOYVWHDVFJY        0.218063        0.237487        0.228497   \n",
       "WFDXOXNFNRHQEC        0.273837        0.184561        0.258525   \n",
       "...                        ...             ...             ...   \n",
       "MGRVRXRGTBOSHW        0.011792        0.035644        0.013072   \n",
       "WELCNKRQSNXMDQ        0.291818        0.206495        0.290592   \n",
       "XFANDVLPSBUGKD        0.304927        0.201923        0.318118   \n",
       "NDTYTMIUWGWIMO        0.146286        0.143836        0.090047   \n",
       "OAUIRSVJXOFAOO        0.302090        0.176124        0.293212   \n",
       "\n",
       "                PZJVSTTVMXPZCJ  ...  VLSRUFWCGBMYDJ  SXXHPCVDFDABHW  \\\n",
       "STZYTFJPGGDRJD        0.316971  ...        0.112832        0.177950   \n",
       "SWTDXMBCOHIACK        0.351300  ...        0.140399        0.184380   \n",
       "HJBWJAPEBGSQPR        0.157643  ...        0.753012        0.152395   \n",
       "VQNWOYVWHDVFJY        0.471683  ...        0.149272        0.216159   \n",
       "WFDXOXNFNRHQEC        0.355102  ...        0.194030        0.212011   \n",
       "...                        ...  ...             ...             ...   \n",
       "MGRVRXRGTBOSHW        0.018998  ...        0.006536        0.015625   \n",
       "WELCNKRQSNXMDQ        0.360465  ...        0.178606        0.203997   \n",
       "XFANDVLPSBUGKD        0.425359  ...        0.197961        0.218633   \n",
       "NDTYTMIUWGWIMO        0.093234  ...        0.073460        0.069132   \n",
       "OAUIRSVJXOFAOO        0.370438  ...        0.160504        0.220690   \n",
       "\n",
       "                MRHAPHFJBAUDTR  ZYCWGZVLCXRARB  CGUNOWXWUXNOPE  \\\n",
       "STZYTFJPGGDRJD        0.277099        0.308905        0.341988   \n",
       "SWTDXMBCOHIACK        0.325533        0.353607        0.387618   \n",
       "HJBWJAPEBGSQPR        0.180529        0.188280        0.147473   \n",
       "VQNWOYVWHDVFJY        0.591716        0.370402        0.279240   \n",
       "WFDXOXNFNRHQEC        0.330603        0.312870        0.318026   \n",
       "...                        ...             ...             ...   \n",
       "MGRVRXRGTBOSHW        0.014568        0.013684        0.010919   \n",
       "WELCNKRQSNXMDQ        0.346317        0.368841        0.374494   \n",
       "XFANDVLPSBUGKD        0.381903        0.373005        0.397096   \n",
       "NDTYTMIUWGWIMO        0.089494        0.114688        0.134598   \n",
       "OAUIRSVJXOFAOO        0.361702        0.360963        0.362445   \n",
       "\n",
       "                MGRVRXRGTBOSHW  WELCNKRQSNXMDQ  XFANDVLPSBUGKD  \\\n",
       "STZYTFJPGGDRJD        0.017219        0.274643        0.298611   \n",
       "SWTDXMBCOHIACK        0.014911        0.364401        0.371447   \n",
       "HJBWJAPEBGSQPR        0.005848        0.199245        0.234842   \n",
       "VQNWOYVWHDVFJY        0.014306        0.288416        0.314224   \n",
       "WFDXOXNFNRHQEC        0.017301        0.319708        0.357045   \n",
       "...                        ...             ...             ...   \n",
       "MGRVRXRGTBOSHW        1.000000        0.016327        0.015598   \n",
       "WELCNKRQSNXMDQ        0.016327        1.000000        0.413747   \n",
       "XFANDVLPSBUGKD        0.015598        0.413747        1.000000   \n",
       "NDTYTMIUWGWIMO        0.018957        0.113171        0.092946   \n",
       "OAUIRSVJXOFAOO        0.016904        0.409401        0.407524   \n",
       "\n",
       "                NDTYTMIUWGWIMO  OAUIRSVJXOFAOO  \n",
       "STZYTFJPGGDRJD        0.138404        0.270531  \n",
       "SWTDXMBCOHIACK        0.153314        0.366841  \n",
       "HJBWJAPEBGSQPR        0.074725        0.180833  \n",
       "VQNWOYVWHDVFJY        0.100515        0.262040  \n",
       "WFDXOXNFNRHQEC        0.083333        0.351071  \n",
       "...                        ...             ...  \n",
       "MGRVRXRGTBOSHW        0.018957        0.016904  \n",
       "WELCNKRQSNXMDQ        0.113171        0.409401  \n",
       "XFANDVLPSBUGKD        0.092946        0.407524  \n",
       "NDTYTMIUWGWIMO        1.000000        0.086003  \n",
       "OAUIRSVJXOFAOO        0.086003        1.000000  \n",
       "\n",
       "[17106 rows x 17106 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tanimoto scores\n",
    "tanimoto_file = os.path.join(data_path, \"ALL_GNPS_210409_positive_tanimoto_scores.pickle\")\n",
    "print(os.path.exists(tanimoto_file))\n",
    "tanimoto_scores_df = pickle.load(open(tanimoto_file, 'rb'))\n",
    "tanimoto_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8921bad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect spectrum peaks...\n",
      "Calculated embedding dimension: 9881.\n",
      "Convert spectrums to binned spectrums...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spectrum binning: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 79475/79475 [00:16<00:00, 4696.20it/s]\n",
      "Create BinnedSpectrum instances: 100%|█████████████████████████████████████████████████████████████████████████████| 79475/79475 [00:01<00:00, 43986.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from ms2deepscore import SpectrumBinner\n",
    "spectrum_binner = SpectrumBinner(10000, mz_min=10.0, mz_max=1000.0, peak_scaling=0.5,\n",
    "                                 allowed_missing_percentage=10.0)\n",
    "binned_spectrums = spectrum_binner.fit_transform(spectrums_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be30f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for num_turns is set from 1 (default) to 2\n",
      "The value for same_prob_bins is set from [(0, 0.5), (0.5, 1)] (default) to [(0.0, 0.1), (0.1, 0.2), (0.2, 0.30000000000000004), (0.30000000000000004, 0.4), (0.4, 0.5), (0.5, 0.6), (0.6000000000000001, 0.7000000000000001), (0.7000000000000001, 0.8), (0.8, 0.9), (0.9, 1.0)]\n",
      "The value for augment_noise_max is set from 10 (default) to 10\n",
      "The value for augment_noise_intensity is set from 0.01 (default) to 0.01\n"
     ]
    }
   ],
   "source": [
    "from ms2deepscore.data_generators import DataGeneratorAllSpectrums, DataGeneratorAllInchikeys\n",
    "dimension = len(spectrum_binner.known_bins)\n",
    "# data_generator = DataGeneratorAllSpectrums(binned_spectrums, tanimoto_scores_df,\n",
    "#                                            dim=dimension)\n",
    "\n",
    "\n",
    "same_prob_bins = list(zip(np.linspace(0,0.9,10), np.linspace(0.1,1,10)))\n",
    "\n",
    "selected_inchikeys = np.unique([s.get(\"inchikey\")[:14] for s in spectrums_filtered])\n",
    "        \n",
    "data_generator = DataGeneratorAllInchikeys(binned_spectrums, selected_inchikeys,\n",
    "                                           tanimoto_scores_df,\n",
    "                                           dim=dimension,\n",
    "                                           same_prob_bins=same_prob_bins,\n",
    "                                           num_turns=2,\n",
    "                                           augment_noise_max=10,\n",
    "                                           augment_noise_intensity=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e6a0fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"base\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " base_input (InputLayer)     [(None, 9881)]            0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 500)               4941000   \n",
      "                                                                 \n",
      " normalization1 (BatchNormal  (None, 500)              2000      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 500)               250500    \n",
      "                                                                 \n",
      " normalization2 (BatchNormal  (None, 500)              2000      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " dropout2 (Dropout)          (None, 500)               0         \n",
      "                                                                 \n",
      " embedding (Dense)           (None, 200)               100200    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,295,700\n",
      "Trainable params: 5,293,700\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n",
      "Model: \"head\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_a (InputLayer)           [(None, 9881)]       0           []                               \n",
      "                                                                                                  \n",
      " input_b (InputLayer)           [(None, 9881)]       0           []                               \n",
      "                                                                                                  \n",
      " base (Functional)              (None, 200)          5295700     ['input_a[0][0]',                \n",
      "                                                                  'input_b[0][0]']                \n",
      "                                                                                                  \n",
      " cosine_similarity (Dot)        (None, 1)            0           ['base[0][0]',                   \n",
      "                                                                  'base[1][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,295,700\n",
      "Trainable params: 5,293,700\n",
      "Non-trainable params: 2,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from ms2deepscore.models import SiameseModel\n",
    "\n",
    "ms2ds_model = SiameseModel(spectrum_binner, base_dims=[500, 500], embedding_dim=200,\n",
    "                           dropout_rate=0.2)\n",
    "ms2ds_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32673104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/louwe015/miniconda3/envs/spec_analysis8/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "454/454 [==============================] - 110s 238ms/step - loss: 0.1022 - val_loss: 0.0945\n",
      "Epoch 2/40\n",
      "454/454 [==============================] - 109s 241ms/step - loss: 0.0940 - val_loss: 0.0907\n",
      "Epoch 3/40\n",
      "454/454 [==============================] - 110s 243ms/step - loss: 0.0908 - val_loss: 0.0892\n",
      "Epoch 4/40\n",
      "454/454 [==============================] - 112s 247ms/step - loss: 0.0884 - val_loss: 0.0855\n",
      "Epoch 5/40\n",
      "454/454 [==============================] - 111s 246ms/step - loss: 0.0859 - val_loss: 0.0842\n",
      "Epoch 6/40\n",
      "454/454 [==============================] - 110s 243ms/step - loss: 0.0859 - val_loss: 0.0836\n",
      "Epoch 7/40\n",
      "454/454 [==============================] - 109s 241ms/step - loss: 0.0830 - val_loss: 0.0807\n",
      "Epoch 8/40\n",
      "454/454 [==============================] - 108s 237ms/step - loss: 0.0826 - val_loss: 0.0809\n",
      "Epoch 9/40\n",
      "454/454 [==============================] - 108s 239ms/step - loss: 0.0827 - val_loss: 0.0799\n",
      "Epoch 10/40\n",
      "454/454 [==============================] - 111s 245ms/step - loss: 0.0813 - val_loss: 0.0796\n",
      "Epoch 11/40\n",
      "454/454 [==============================] - 107s 237ms/step - loss: 0.0816 - val_loss: 0.0806\n",
      "Epoch 12/40\n",
      "454/454 [==============================] - 106s 234ms/step - loss: 0.0822 - val_loss: 0.0804\n",
      "Epoch 13/40\n",
      "454/454 [==============================] - 106s 235ms/step - loss: 0.0821 - val_loss: 0.0808\n",
      "Epoch 14/40\n",
      "454/454 [==============================] - 105s 231ms/step - loss: 0.0818 - val_loss: 0.0795\n",
      "Epoch 15/40\n",
      "454/454 [==============================] - 107s 236ms/step - loss: 0.0810 - val_loss: 0.0794\n",
      "Epoch 16/40\n",
      "454/454 [==============================] - 105s 232ms/step - loss: 0.0811 - val_loss: 0.0789\n",
      "Epoch 17/40\n",
      "454/454 [==============================] - 102s 225ms/step - loss: 0.0796 - val_loss: 0.0772\n",
      "Epoch 18/40\n",
      "454/454 [==============================] - 103s 228ms/step - loss: 0.0788 - val_loss: 0.0763\n",
      "Epoch 19/40\n",
      "454/454 [==============================] - 103s 227ms/step - loss: 0.0784 - val_loss: 0.0772\n",
      "Epoch 20/40\n",
      "454/454 [==============================] - 104s 230ms/step - loss: 0.0787 - val_loss: 0.0770\n",
      "Epoch 21/40\n",
      "454/454 [==============================] - 103s 227ms/step - loss: 0.0783 - val_loss: 0.0760\n",
      "Epoch 22/40\n",
      "454/454 [==============================] - 107s 235ms/step - loss: 0.0782 - val_loss: 0.0758\n",
      "Epoch 23/40\n",
      "454/454 [==============================] - 107s 236ms/step - loss: 0.0779 - val_loss: 0.0756\n",
      "Epoch 24/40\n",
      "454/454 [==============================] - 107s 236ms/step - loss: 0.0773 - val_loss: 0.0743\n",
      "Epoch 25/40\n",
      "454/454 [==============================] - 105s 231ms/step - loss: 0.0756 - val_loss: 0.0745\n",
      "Epoch 26/40\n",
      "454/454 [==============================] - 105s 231ms/step - loss: 0.0753 - val_loss: 0.0732\n",
      "Epoch 27/40\n",
      "454/454 [==============================] - 106s 233ms/step - loss: 0.0757 - val_loss: 0.0752\n",
      "Epoch 28/40\n",
      "454/454 [==============================] - 106s 233ms/step - loss: 0.0761 - val_loss: 0.0725\n",
      "Epoch 29/40\n",
      "454/454 [==============================] - 109s 241ms/step - loss: 0.0755 - val_loss: 0.0724\n",
      "Epoch 30/40\n",
      "454/454 [==============================] - 106s 233ms/step - loss: 0.0748 - val_loss: 0.0716\n",
      "Epoch 31/40\n",
      "454/454 [==============================] - 105s 231ms/step - loss: 0.0740 - val_loss: 0.0731\n",
      "Epoch 32/40\n",
      "454/454 [==============================] - 109s 241ms/step - loss: 0.0758 - val_loss: 0.0728\n",
      "Epoch 33/40\n",
      "454/454 [==============================] - 111s 246ms/step - loss: 0.0737 - val_loss: 0.0698\n",
      "Epoch 34/40\n",
      "454/454 [==============================] - 109s 240ms/step - loss: 0.0721 - val_loss: 0.0699\n",
      "Epoch 35/40\n",
      "454/454 [==============================] - 111s 244ms/step - loss: 0.0740 - val_loss: 0.0714\n",
      "Epoch 36/40\n",
      "454/454 [==============================] - 106s 234ms/step - loss: 0.0730 - val_loss: 0.0710\n",
      "Epoch 37/40\n",
      "454/454 [==============================] - 107s 236ms/step - loss: 0.0729 - val_loss: 0.0709\n",
      "Epoch 38/40\n",
      "454/454 [==============================] - 107s 235ms/step - loss: 0.0729 - val_loss: 0.0696\n",
      "Epoch 39/40\n",
      "454/454 [==============================] - 107s 236ms/step - loss: 0.0716 - val_loss: 0.0701\n",
      "Epoch 40/40\n",
      "454/454 [==============================] - 109s 239ms/step - loss: 0.0720 - val_loss: 0.0696\n"
     ]
    }
   ],
   "source": [
    "ms2ds_model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "ms2ds_model.fit(\n",
    "    data_generator,\n",
    "    validation_data=data_generator,\n",
    "    epochs=40)  # could also make some validation data and include early stopping etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a5ec548",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2ds_model_out = os.path.join(path_models, base+\"_only_train_ms2ds_10k_500_500_200.hdf5\")\n",
    "ms2ds_model.save(ms2ds_model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87276aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ms2deepscore import MS2DeepScore\n",
    "ms2ds_score = MS2DeepScore(ms2ds_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3663a763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms2ds_score.model.spectrum_binner.allowed_missing_percentage = 50\n",
    "ms2ds_score.model.spectrum_binner.allowed_missing_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ac46e",
   "metadata": {},
   "source": [
    "### code from ms2query for including validation data and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save best model and include early stopping\n",
    "# epochs = 150\n",
    "# learning_rate = 0.001\n",
    "# import tensorflow as tf\n",
    "# metrics = [\"mae\", tf.keras.metrics.RootMeanSquaredError()]\n",
    "\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from datetime import datetime\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# # Parameters\n",
    "# patience_scoring_net = 5\n",
    "# embedding_dim = 200\n",
    "# filename_base = f\"{timestamp}_data210409_10k_500_500_{embedding_dim}\"\n",
    "# model_output_file = os.path.join(path_data, \"trained_models\" , filename_base+\".hdf5\")\n",
    "\n",
    "# model.compile(\n",
    "#     loss='mse',\n",
    "#     optimizer=Adam(lr=learning_rate),\n",
    "#     metrics=metrics)\n",
    "\n",
    "# checkpointer = ModelCheckpoint(\n",
    "#     filepath = model_output_file,\n",
    "#     monitor='val_loss', mode=\"min\",\n",
    "#     verbose=1,\n",
    "#     save_best_only=True\n",
    "#     )\n",
    "\n",
    "# earlystopper_scoring_net = EarlyStopping(\n",
    "#     monitor='val_loss', mode=\"min\",\n",
    "#     patience=patience_scoring_net,\n",
    "#     verbose=1\n",
    "#     )\n",
    "\n",
    "# history = model.model.fit(training_generator,\n",
    "#     validation_data=validation_generator,\n",
    "#     epochs = epochs,\n",
    "#     verbose=1, \n",
    "#     callbacks = [\n",
    "#         earlystopper_scoring_net,\n",
    "#         checkpointer,\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "# # Save history\n",
    "# filename = os.path.join(path_output, filename_base+'_training_history.pickle')\n",
    "# with open(filename, 'wb') as f:\n",
    "#     pickle.dump(history.history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
